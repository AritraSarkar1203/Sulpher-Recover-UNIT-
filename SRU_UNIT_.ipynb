{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRg1m7L7AQBape/ptoH6Lz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AritraSarkar1203/Sulpher-Recover-UNIT-/blob/main/SRU_UNIT_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Consider Both output in one time"
      ],
      "metadata": {
        "id": "sWtLwzFerY1_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylsYBeM2iZZ9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load your SRU dataset\n",
        "in_df = pd.read_csv(\"/content/IN_Table.csv\")  # columns: x1...x5\n",
        "out_df = pd.read_csv(\"/content/OUT_Table.csv\") # columns: y1, y2\n",
        "\n",
        "# Combine input and output dataframes\n",
        "df = pd.concat([in_df, out_df], axis=1)\n",
        "\n",
        "\n",
        "X = df.iloc[:, 0:5].values  # Inputs\n",
        "y = df.iloc[:, 5:7].values  # Outputs\n",
        "\n",
        "# Scale features for better kNN graph building\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfca6fab",
        "outputId": "a1ad1b39-3993-4179-a023-5f1aef9c0710"
      },
      "source": [
        "!pip install torch_geometric"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.14.1)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import kneighbors_graph, radius_neighbors_graph\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np\n",
        "\n",
        "# Use training data for graph construction and features\n",
        "x_train_scaled = X_train[:, 0:5]\n",
        "y_train_data = y_train[:, 0:2]\n",
        "\n",
        "# Create kNN graph on the training data\n",
        "A = kneighbors_graph(x_train_scaled, n_neighbors=10, mode='connectivity', include_self=False)\n",
        "\n",
        "# Convert the tuple of arrays from nonzero() to a single numpy array before creating the tensor\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)\n",
        "\n",
        "# Convert to PyG Data using scaled training features and training labels\n",
        "x = torch.tensor(x_train_scaled, dtype=torch.float)\n",
        "y = torch.tensor(y_train_data, dtype=torch.float) # Remove unsqueeze(1)\n",
        "\n",
        "graph_data = Data(x=x, edge_index=edge_index, y=y)"
      ],
      "metadata": {
        "id": "sMahLEmhj7_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch_geometric.nn import TransformerConv\n",
        "\n",
        "class GNNModel(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GNNModel, self).__init__()\n",
        "        self.conv1 = TransformerConv(in_channels, hidden_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = TransformerConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x"
      ],
      "metadata": {
        "id": "VnCtTvshkbGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=GNNModel(in_channels=5,hidden_channels=32,out_channels=2)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.MSELoss()\n",
        "losses=[]\n",
        "\n",
        "epochs=500\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(graph_data)\n",
        "    loss = criterion(out, graph_data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    losses.append(loss.item())\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{epochs} , Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iJE5GW2k1Ik",
        "outputId": "bebf6e11-6525-44e0-d064-a400707c1c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/500 , Loss: 0.6044\n",
            "Epoch 200/500 , Loss: 0.5491\n",
            "Epoch 300/500 , Loss: 0.5115\n",
            "Epoch 400/500 , Loss: 0.4938\n",
            "Epoch 500/500 , Loss: 0.4833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = model(graph_data).numpy()\n",
        "    true = graph_data.y.numpy()\n",
        "    rmse = mean_squared_error(true, predictions)\n",
        "    r2 = r2_score(true, predictions)\n",
        "    print(f\"RMSE: {rmse:.4f}, R²: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrCaVPiGp2E6",
        "outputId": "77ba81c6-5201-4fe4-ece3-908098a36ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.4840, R²: 0.5214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Consider only 1 output from NN"
      ],
      "metadata": {
        "id": "mUuTQGQxrS-b"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddc6e3e8"
      },
      "source": [
        "# Combine input and output dataframes\n",
        "df = pd.concat([in_df, out_df], axis=1)\n",
        "\n",
        "\n",
        "X = df.iloc[:, 0:5].values  # Inputs\n",
        "y = df.iloc[:, 5:6].values  # Select only the first output column\n",
        "#y = df.iloc[:, 6:7].values\n",
        "# Scale features for better kNN graph building\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc8cb753"
      },
      "source": [
        "# Use training data for graph construction and features\n",
        "x_train_scaled = X_train[:, 0:5]\n",
        "y_train_data = y_train[:, 0] # Select only the first output column from the training data\n",
        "\n",
        "# Create kNN graph on the training data\n",
        "A = kneighbors_graph(x_train_scaled, n_neighbors=5, mode='connectivity', include_self=False)\n",
        "\n",
        "# Convert the tuple of arrays from nonzero() to a single numpy array before creating the tensor\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)\n",
        "\n",
        "# Convert to PyG Data using scaled training features and training labels\n",
        "x = torch.tensor(x_train_scaled, dtype=torch.float)\n",
        "y = torch.tensor(y_train_data, dtype=torch.float).unsqueeze(1) # Ensure y is a column vector\n",
        "\n",
        "graph_data = Data(x=x, edge_index=edge_index, y=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de6cd537"
      },
      "source": [
        "import torch.nn as nn\n",
        "from torch_geometric.nn import TransformerConv\n",
        "\n",
        "class GNNModel(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GNNModel, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 =GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d54b5a9",
        "outputId": "260d49af-8fd5-4a10-896e-96018fbc9fae"
      },
      "source": [
        "model=GNNModel(in_channels=5,hidden_channels=32,out_channels=1)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.MSELoss()\n",
        "losses=[]\n",
        "\n",
        "epochs=1000\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(graph_data)\n",
        "    loss = criterion(out, graph_data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    losses.append(loss.item())\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{epochs} , Loss: {loss.item():.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/1000 , Loss: 0.5421\n",
            "Epoch 200/1000 , Loss: 0.5082\n",
            "Epoch 300/1000 , Loss: 0.4944\n",
            "Epoch 400/1000 , Loss: 0.4846\n",
            "Epoch 500/1000 , Loss: 0.4749\n",
            "Epoch 600/1000 , Loss: 0.4669\n",
            "Epoch 700/1000 , Loss: 0.4630\n",
            "Epoch 800/1000 , Loss: 0.4604\n",
            "Epoch 900/1000 , Loss: 0.4580\n",
            "Epoch 1000/1000 , Loss: 0.4558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFrDBrjgq7RV",
        "outputId": "406401c1-74c3-41a7-cd5d-66fa1c3eae4e"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = model(graph_data).numpy()\n",
        "    true = graph_data.y.numpy()\n",
        "\n",
        "    # Select the single output column (which is the first column now)\n",
        "    true_single = true[:, 0]\n",
        "    predictions_single = predictions[:, 0]\n",
        "\n",
        "    # Calculate metrics for the single output column\n",
        "    mse = mean_squared_error(true_single, predictions_single)\n",
        "    rmse = np.sqrt(mse) # Calculate RMSE by taking the square root of MSE\n",
        "    r2 = r2_score(true_single, predictions_single)\n",
        "\n",
        "    print(f\"RMSE: {rmse:.4f}, R²: {r2:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.6631, R²: 0.5626\n"
          ]
        }
      ]
    }
  ]
}